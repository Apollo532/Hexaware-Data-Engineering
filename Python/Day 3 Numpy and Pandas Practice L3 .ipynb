{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7234a1db-f9d3-449a-b116-133e82ab3c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35436f-2e7b-4ad6-a7f6-67bdfb8dbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Find all the indices of peaks in a 1D numpy array.\n",
    "n = np.array([2, 7, 1, 3, 7, 1, 2, 6, 0, 1, 3, 7, 6])\n",
    "arr = []\n",
    "i = 1\n",
    "while i < len(n)-1:\n",
    "    if n[i] > n[i-1] and n[i] > n[i+1]:\n",
    "        arr.append(i)\n",
    "        i += 1\n",
    "print (arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f6c250f-cd7c-4008-bf3c-ffc724fce5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1]\n",
      " [1 0 1 0 1 0 1 0]\n",
      " [0 1 0 1 0 1 0 1]\n",
      " [1 0 1 0 1 0 1 0]\n",
      " [0 1 0 1 0 1 0 1]\n",
      " [1 0 1 0 1 0 1 0]\n",
      " [0 1 0 1 0 1 0 1]\n",
      " [1 0 1 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#Q2. Create an 8x8 chessboard pattern matrix.\n",
    "board = np.zeros((8,8), dtype = int)\n",
    "board[1::2, ::2] = 1\n",
    "board[::2, 1::2] = 1\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "735a208d-b902-4e64-821c-7dc3dbaf910b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Q3. Perform One-Hot Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([0, 1, 2, 3, 1, 2])\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "one_hot = encoder.fit_transform(arr.reshape(-1, 1))\n",
    "\n",
    "print( one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "172c8d21-0a19-484d-8acd-f151adf951c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates in April 1994:\n",
      " DatetimeIndex(['1994-04-01', '1994-04-02', '1994-04-03', '1994-04-04',\n",
      "               '1994-04-05', '1994-04-06', '1994-04-07', '1994-04-08',\n",
      "               '1994-04-09', '1994-04-10', '1994-04-11', '1994-04-12',\n",
      "               '1994-04-13', '1994-04-14', '1994-04-15', '1994-04-16',\n",
      "               '1994-04-17', '1994-04-18', '1994-04-19', '1994-04-20',\n",
      "               '1994-04-21', '1994-04-22', '1994-04-23', '1994-04-24',\n",
      "               '1994-04-25', '1994-04-26', '1994-04-27', '1994-04-28',\n",
      "               '1994-04-29', '1994-04-30'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "Number of weekdays: 21\n",
      "Was 7th April 1994 a weekday? True\n"
     ]
    }
   ],
   "source": [
    "#Q4. Display all dates for April 1994 and check weekdays.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dates = pd.date_range(start='1994-04-01', end='1994-04-30')\n",
    "weekdays_c = (dates.weekday < 5).sum()\n",
    "is_weekday = pd.Timestamp('1994-04-07').weekday() < 5\n",
    "\n",
    "print(\"Dates in April 1994:\\n\", dates)\n",
    "print(\"Number of weekdays:\", weekdays_c)\n",
    "print(\"Was 7th April 1994 a weekday?\", is_weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3a51b2b-d9dc-4d3d-8588-1679a95d3ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded array:\n",
      " [[7. 7. 7. 7. 7. 7. 7. 7. 7.]\n",
      " [7. 7. 7. 7. 7. 7. 7. 7. 7.]\n",
      " [7. 7. 1. 1. 1. 1. 1. 7. 7.]\n",
      " [7. 7. 1. 2. 2. 2. 1. 7. 7.]\n",
      " [7. 7. 1. 2. 2. 2. 1. 7. 7.]\n",
      " [7. 7. 1. 2. 2. 2. 1. 7. 7.]\n",
      " [7. 7. 1. 1. 1. 1. 1. 7. 7.]\n",
      " [7. 7. 7. 7. 7. 7. 7. 7. 7.]\n",
      " [7. 7. 7. 7. 7. 7. 7. 7. 7.]]\n",
      "Inner product of the array:\n",
      " [[441. 441. 231. 252. 252. 252. 231. 441. 441.]\n",
      " [441. 441. 231. 252. 252. 252. 231. 441. 441.]\n",
      " [231. 231. 201. 204. 204. 204. 201. 231. 231.]\n",
      " [252. 252. 204. 210. 210. 210. 204. 252. 252.]\n",
      " [252. 252. 204. 210. 210. 210. 204. 252. 252.]\n",
      " [252. 252. 204. 210. 210. 210. 204. 252. 252.]\n",
      " [231. 231. 201. 204. 204. 204. 201. 231. 231.]\n",
      " [441. 441. 231. 252. 252. 252. 231. 441. 441.]\n",
      " [441. 441. 231. 252. 252. 252. 231. 441. 441.]]\n"
     ]
    }
   ],
   "source": [
    "#Q5. Create a 5x5 array with 1 on the border and 2 inside, pad with a border of 7's.\n",
    "\n",
    "arr = np.ones((5, 5)) * 2  #2s inside\n",
    "arr[0, :] = arr[:, 0] = arr[-1, :] = arr[:, -1] = 1  #border of 1s\n",
    "\n",
    "padded_arr = np.pad(arr, pad_width=2, mode='constant', constant_values=7) #padding of 7\n",
    "inner_product = np.inner(padded_arr, padded_arr)\n",
    "\n",
    "print(\"Padded array:\\n\", padded_arr)\n",
    "print(\"Inner product of the array:\\n\", inner_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84b3d7-ff7d-4888-ae22-6933e668e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Count the difference back to the previous 7 (or the start).\n",
    "df = pd.DataFrame({'int': [7, 2, 0, 7, 4, 2, 5, 7, 3, 5]})\n",
    "df1 = df\n",
    "df1['shift'] = df1['int'].shift(7)\n",
    "startVal = df1['int'][0]\n",
    "df1 = df1.fillna(startVal)\n",
    "print (df1)\n",
    "df1['A'] = df1['int'] - df1['shift']\n",
    "print(df1['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "823ef8ba-0036-4d9f-8a3b-6182175caa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data (merge1):\n",
      "   subject_id first_name last_name  test_id\n",
      "0          1       Alex  Anderson       51\n",
      "1          2        Amy  Ackerman       15\n",
      "2          3      Allen       Ali       15\n",
      "3          4      Alice      Aoni       61\n",
      "4          4      Billy    Bonder       61\n",
      "5          5     Ayoung   Atiches       16\n",
      "6          5      Brian     Black       16\n",
      "7          7      Bryce     Brice       14\n",
      "8          8      Betty    Btisan       15\n",
      "Outer merge (merge2):\n",
      "   subject_id first_name last_name\n",
      "0          1       Alex  Anderson\n",
      "1          2        Amy  Ackerman\n",
      "2          3      Allen       Ali\n",
      "3          4      Alice      Aoni\n",
      "4          5     Ayoung   Atiches\n",
      "5          4      Billy    Bonder\n",
      "6          5      Brian     Black\n",
      "7          6       Bran   Balwner\n",
      "8          7      Bryce     Brice\n",
      "9          8      Betty    Btisan\n"
     ]
    }
   ],
   "source": [
    "#Q7. Join dfs and perform merges\n",
    "\n",
    "raw_data_1 = {'subject_id': ['1', '2', '3', '4', '5'], 'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], 'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "raw_data_2 = {'subject_id': ['4', '5', '6', '7', '8'], 'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], 'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "raw_data_3 = {'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'], 'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}\n",
    "\n",
    "data1 = pd.DataFrame(raw_data_1)\n",
    "data2 = pd.DataFrame(raw_data_2)\n",
    "data3 = pd.DataFrame(raw_data_3)\n",
    "\n",
    "data_all_row = pd.concat([data1, data2])\n",
    "merge1 = pd.merge(data_all_row, data3, on='subject_id')\n",
    "merge2 = pd.merge(data1, data2, how='outer')\n",
    "\n",
    "print(\"Merged data (merge1):\\n\", merge1)\n",
    "print(\"Outer merge (merge2):\\n\", merge2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81fcb1e-5a6f-40f9-927b-8db2ee80dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8. Analyzing the army dataframe\n",
    "\n",
    "raw_data = {\n",
    "    'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'],\n",
    "    'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd'],\n",
    "    'deaths': [523, 52, 25, 616, 43, 234, 523, 62, 62, 73, 37, 35],\n",
    "    'veterans': [1, 5, 62, 26, 73, 37, 949, 48, 48, 435, 63, 345],\n",
    "    'origin': ['Arizona', 'California', 'Texas', 'Florida', 'Maine', 'Iowa', 'Alaska', 'Washington', 'Oregon', 'Wyoming', 'Louisana', 'Georgia']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "df.set_index('origin', inplace=True)\n",
    "total_veterans = df['veterans'].sum()\n",
    "deaths_filter = df[(df['deaths'] > 450) | (df['deaths'] < 45)]\n",
    "non_dragoons = df[df['regiment'] != 'Dragoons']\n",
    "texas_arizona = df.loc[['Texas', 'Arizona']]\n",
    "fifth_cell = df.loc['Texas'].iloc[:,4]\n",
    "\n",
    "print(\"Total veterans:\", total_veterans)\n",
    "print(\"Rows where deaths > 450 or deaths < 45:\\n\", deaths_filter)\n",
    "print(\"Non-Dragoons:\\n\", non_dragoons)\n",
    "print(\"Texas and Arizona:\\n\", texas_arizona)\n",
    "print(\"Fifth cell in Texas row:\", fifth_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f7da791-ef6d-413b-a25c-04b0d0c8629b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with at least 2 vowels capitalized:  0      INSAID\n",
      "1     STRIVES\n",
      "3    BRINGING\n",
      "4         OUT\n",
      "8         YOU\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Q9. Filter and capitalize words with at least 2 vowels\n",
    "\n",
    "series = pd.Series(['Insaid', 'strives', 'for', 'bringing', 'out', 'the', 'best', 'in', 'you'])\n",
    "vowel_filtered = series[series.str.count(r'[aeiouAEIOU]') >= 2].str.upper()\n",
    "\n",
    "print(\"Words with at least 2 vowels capitalized: \", vowel_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66c56889-320f-486d-8471-1b0549900bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after swapping rows and reversing columns:\n",
      "     0   1   2   3\n",
      "3   8   9  10  11\n",
      "2  12  13  14  15\n",
      "1   4   5   6   7\n",
      "0   0   1   2   3\n"
     ]
    }
   ],
   "source": [
    "#Q 10. Create a dataframe from a 4*4 array containing elements from 0 to15 in a squential order. Swap rows third\n",
    "#and fourth by creating a generic function to swap two rows. Now print the dataframe obtained after reversing the\n",
    "#elements of each column.\n",
    "\n",
    "df = pd.DataFrame(np.arange(16).reshape(4, 4))\n",
    "\n",
    "def swap_rows(df, row1, row2):\n",
    "    df.iloc[[row1, row2]] = df.iloc[[row2, row1]]\n",
    "\n",
    "swap_rows(df, 2, 3)\n",
    "df_reversed = df.apply(lambda col: col[::-1])\n",
    "\n",
    "print(\"DataFrame after swapping rows and reversing columns:\\n\", df_reversed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
